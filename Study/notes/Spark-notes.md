# Data Requirements
* Collection / Ingestion
* Storage
* Processing
* Retrieval

# Need of distributed data storage and processing
Vertical scalability was fine until data volumes and processing/computation power/needs grown to a unmanagable level with vertical scalaibility.

Google was the company to realize this, do research and create abusiness around it. Google started trying to solve above "Data Requirements" at larger scale.
Google released 2 whitepapers to solve Data Storage and Processing needs via GFS (2003) and MapReduce (2004) respectively. These whitepapers led to the invention of HDFS and Hadoop MapReduce.

# HADOOP Ecosystem
<img width="1601" alt="image" src="https://user-images.githubusercontent.com/8909535/167064327-8ed4ce01-7167-4c0e-bafe-f0d127e1c080.png">

# Datalake

# What is Spark
Apache Spark started at UC Berkeley in 2009, and open sourced in 2010 under a BSD license. In 2013, the project was donated to the Apache Software Foundation and switched its license to Apache 2.0. In February 2014, Spark became a Top-Level Apache Project.

<img width="1096" alt="image" src="https://user-images.githubusercontent.com/8909535/167064754-c8b14fcf-52da-42e5-bba9-cf0207650006.png">


# Why Spark

# Spark Development environments

# Installation

# Run Hello World program

# Run Hello World program

# How Spark program runs

